{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10976606,"sourceType":"datasetVersion","datasetId":6830339}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets ipywidgets peft bitsandbytes accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T07:12:43.110898Z","iopub.execute_input":"2025-03-10T07:12:43.111186Z","iopub.status.idle":"2025-03-10T07:12:50.571756Z","shell.execute_reply.started":"2025-03-10T07:12:43.111148Z","shell.execute_reply":"2025-03-10T07:12:50.570791Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.5)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.13)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (75.1.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport math\nimport numpy as np\nimport torch\nfrom tqdm.auto import tqdm \nfrom datetime import timedelta\nimport time\nimport gc\nfrom peft import prepare_model_for_kbit_training\n\n# Set memory optimization environment variable\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    Trainer,\n    TrainingArguments,\n    DataCollatorForLanguageModeling,\n    TrainerCallback\n)\nfrom datasets import load_dataset, Dataset\nfrom peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n\n# Free up memory before starting\ntorch.cuda.empty_cache()\ngc.collect()\n\n# 1. Load your text dataset from the Kaggle input path\nwith open('/kaggle/input/nbody-data/cleaned.md', 'r', encoding='utf-8') as f:\n    corpus = f.read()\n\n# 2. Load the tokenizer and determine the model's maximum context length\nmodel_name = \"Qwen/Qwen2.5-Math-1.5B\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmax_context_length = tokenizer.model_max_length\nprint(f\"Maximum context length: {max_context_length}\")\n\n# Use smaller chunks to further reduce memory pressure\nchunk_size = 2048  # Further reduced from 4096\n\n# 3. Tokenize the entire corpus and split it into reasonably sized chunks\ndef prepare_corpus_for_training(corpus, tokenizer, chunk_size):\n    tokens = tokenizer(corpus, truncation=False, return_tensors=\"np\")[\"input_ids\"][0]\n    \n    total_chunks = math.ceil(len(tokens) / chunk_size)\n    print(f\"Total tokens: {len(tokens)}, Creating {total_chunks} chunks of size {chunk_size}\")\n    \n    chunks = []\n    for i in range(0, len(tokens), chunk_size):\n        chunk = tokens[i:i + chunk_size].tolist()\n        if len(chunk) < chunk_size:\n            chunk = chunk + [tokenizer.pad_token_id] * (chunk_size - len(chunk))\n        chunks.append({\"input_ids\": chunk})\n    \n    return Dataset.from_list(chunks)\n\nchunked_dataset = prepare_corpus_for_training(corpus, tokenizer, chunk_size)\n\n# 4. Create a unified progress tracking callback\nclass EnhancedProgressCallback(TrainerCallback):\n    def __init__(self):\n        self.training_start = time.time()\n        self.epoch_start = None\n        self.progress_bar = None\n        self.current_epoch = 0\n        \n    def on_train_begin(self, args, state, control, **kwargs):\n        print(f\"\\n{'='*70}\")\n        print(f\"TRAINING STARTED\")\n        print(f\"{'='*70}\")\n        \n        # Calculate total steps for all epochs\n        self.total_steps = state.max_steps\n        self.steps_per_epoch = len(trainer.train_dataset) // (args.per_device_train_batch_size * \n                                                            args.gradient_accumulation_steps * \n                                                            torch.cuda.device_count())  # Account for multi-GPU\n    \n    def on_epoch_begin(self, args, state, control, **kwargs):\n        self.epoch_start = time.time()\n        self.current_epoch = state.epoch + 1\n        \n        print(f\"\\n{'='*70}\")\n        print(f\"Beginning Epoch {self.current_epoch}/{args.num_train_epochs}\")\n        print(f\"{'='*70}\")\n        \n        # Create a progress bar for this epoch\n        self.progress_bar = tqdm(\n            total=self.steps_per_epoch, \n            desc=f\"Epoch {self.current_epoch}/{args.num_train_epochs}\",\n            position=0\n        )\n        self.last_logged_step = 0\n        \n    def on_epoch_end(self, args, state, control, **kwargs):\n        # Close progress bar\n        if self.progress_bar:\n            self.progress_bar.close()\n        \n        # Calculate epoch time\n        epoch_time = time.time() - self.epoch_start\n        total_time = time.time() - self.training_start\n        \n        print(f\"\\n{'='*70}\")\n        print(f\"Completed Epoch {self.current_epoch}/{args.num_train_epochs}\")\n        print(f\"Epoch time: {timedelta(seconds=int(epoch_time))}\")\n        print(f\"Total training time: {timedelta(seconds=int(total_time))}\")\n        \n        # Estimate remaining time\n        epochs_remaining = args.num_train_epochs - self.current_epoch\n        est_remaining = epoch_time * epochs_remaining\n        print(f\"Estimated time remaining: {timedelta(seconds=int(est_remaining))}\")\n        print(f\"{'='*70}\\n\")\n        \n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if state.is_local_process_zero and logs and self.progress_bar:\n            # Calculate step progress\n            current_step_in_epoch = state.global_step % self.steps_per_epoch\n            if current_step_in_epoch == 0 and state.global_step > 0:\n                current_step_in_epoch = self.steps_per_epoch\n                \n            # Update progress bar to current position\n            self.progress_bar.n = current_step_in_epoch\n            \n            # Add metrics to progress bar\n            postfix_dict = {}\n            if \"loss\" in logs:\n                postfix_dict[\"loss\"] = f\"{logs['loss']:.4f}\"\n            if \"learning_rate\" in logs:\n                postfix_dict[\"lr\"] = f\"{logs['learning_rate']:.2e}\"\n            \n            # Add GPU memory usage\n            try:\n                allocated = torch.cuda.memory_allocated() / (1024 ** 3)\n                postfix_dict[\"GPU\"] = f\"{allocated:.1f}GB\"\n            except:\n                pass\n                \n            self.progress_bar.set_postfix(**postfix_dict)\n            self.progress_bar.update(0)  # Force refresh\n            \n            # Print step details with percentage completed\n            current_overall = state.global_step\n            progress_percent = current_overall / self.total_steps * 100\n            if current_overall % 20 == 0:  # Print every 20 steps\n                print(f\"Step: {current_overall}/{self.total_steps} ({progress_percent:.1f}%) | \"\n                      f\"Loss: {logs.get('loss', 0):.4f} | \"\n                      f\"LR: {logs.get('learning_rate', 0):.2e}\")\n\n# Create data collator\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)\n\n# 5. LoRA-optimized training arguments for continued pretraining\ntraining_args = TrainingArguments(\n    output_dir=\"./qwen_math_nbody_lora\",\n    overwrite_output_dir=True,\n    num_train_epochs=3,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=16,\n    # Standard learning rate for non-embedding layers\n    learning_rate=1e-4,\n    weight_decay=0.01,\n    logging_steps=10,\n    save_steps=100,\n    save_total_limit=3,\n    dataloader_drop_last=True,\n    report_to=[\"tensorboard\"],\n    fp16=True,\n    logging_first_step=True,\n    gradient_checkpointing=True,\n    logging_dir=\"./logs\",\n    warmup_steps=100,\n    logging_strategy=\"steps\",\n    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n    # Use adamw_hf which better supports parameter groups for decoupled learning rates\n    optim=\"adamw_hf\"\n)\n\n# 6. Load model for examination to identify all module names\nprint(\"Loading model to identify layer structure...\")\ntemp_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    use_cache=False,\n    torch_dtype=torch.float16,\n    device_map={\"\": 0}  # Load on first GPU only temporarily\n)\n\n# Identify embedding and other linear layers for targeting\nembedding_layers = []\nlinear_layers = []\nfor name, module in temp_model.named_modules():\n    if 'embed' in name.lower() or 'lm_head' in name.lower():\n        embedding_layers.append(name)\n    elif isinstance(module, torch.nn.Linear) and 'embed' not in name.lower() and 'lm_head' not in name.lower():\n        linear_layers.append(name)\n\nprint(f\"Found {len(embedding_layers)} embedding layers: {embedding_layers}\")\nprint(f\"Found {len(linear_layers)} linear layers\")\n\n# Clean up memory\ndel temp_model\ntorch.cuda.empty_cache()\ngc.collect()\n\n# 7. Comprehensive LoRA configuration for continued pretraining\n# Combine both standard target_modules and add embedding layers\n# List adjusted based on Qwen2.5 specific architecture\nlora_config = LoraConfig(\n    r=8,                            # Reduced from 16\n    lora_alpha=16,                  # Reduced from 32\n    target_modules=[                # Only target key modules\n        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n        \"gate_proj\", \"up_proj\", \"down_proj\", \"wte\", \"lm_head\"\n    ],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=TaskType.CAUSAL_LM,\n)\n\n# 8. Initialize model with optimized settings\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    use_cache=False, # Load in fp16 for further efficiency\n    device_map=\"auto\"\n)\n\n# 9. Apply LoRA to the model\nprint(\"Applying LoRA adapters to model...\")\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n\n# 10. Create custom optimizer with decoupled learning rates\ndef get_optimizer_grouped_parameters(model, embedding_lr=1e-5, non_embedding_lr=1e-4):\n    \"\"\"Create parameter groups with different learning rates for embeddings vs other layers.\"\"\"\n    no_decay = [\"bias\", \"LayerNorm.weight\"]\n    embedding_names = [\"wte\", \"lm_head\"]\n    \n    optimizer_grouped_parameters = [\n        # Embedding params with lower learning rate and no weight decay\n        {\n            \"params\": [p for n, p in model.named_parameters() \n                      if any(nd in n for nd in embedding_names) and p.requires_grad],\n            \"lr\": embedding_lr,\n            \"weight_decay\": 0.0,\n        },\n        # Non-embedding params with regular learning rate and weight decay\n        {\n            \"params\": [p for n, p in model.named_parameters() \n                      if not any(nd in n for nd in embedding_names) \n                      and not any(nd in n for nd in no_decay) and p.requires_grad],\n            \"lr\": non_embedding_lr,\n            \"weight_decay\": training_args.weight_decay,\n        },\n        # Non-embedding params with regular learning rate and no weight decay\n        {\n            \"params\": [p for n, p in model.named_parameters() \n                      if not any(nd in n for nd in embedding_names) \n                      and any(nd in n for nd in no_decay) and p.requires_grad],\n            \"lr\": non_embedding_lr,\n            \"weight_decay\": 0.0,\n        },\n    ]\n    return optimizer_grouped_parameters\n\n# 11. Create a custom trainer with decoupled learning rates\nclass CustomPEFTTrainer(Trainer):\n    def create_optimizer(self):\n        \"\"\"Create optimizer with separate learning rates for embedding vs. non-embedding parameters\"\"\"\n        if self.optimizer is None:\n            # Create parameter groups with decoupled learning rates\n            embedding_lr = self.args.learning_rate / 10  # Lower embedding LR (10x smaller)\n            non_embedding_lr = self.args.learning_rate\n            \n            print(f\"Using decoupled learning rates: embedding={embedding_lr}, other={non_embedding_lr}\")\n            \n            optimizer_grouped_parameters = get_optimizer_grouped_parameters(\n                self.model, \n                embedding_lr=embedding_lr,\n                non_embedding_lr=non_embedding_lr\n            )\n            \n            # Create optimizer with parameter groups\n            self.optimizer = torch.optim.AdamW(\n                optimizer_grouped_parameters,\n                lr=self.args.learning_rate,\n                betas=(0.9, 0.999),\n                eps=1e-8,\n            )\n        \n        return self.optimizer\n\n# 12. Initialize custom trainer with all optimizations\nprogress_callback = EnhancedProgressCallback()\ntrainer = CustomPEFTTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=chunked_dataset,\n    data_collator=data_collator,\n)\ntrainer.add_callback(progress_callback)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T07:12:50.573195Z","iopub.execute_input":"2025-03-10T07:12:50.573502Z","iopub.status.idle":"2025-03-10T07:13:49.226757Z","shell.execute_reply.started":"2025-03-10T07:12:50.573479Z","shell.execute_reply":"2025-03-10T07:13:49.225436Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ce4d89af38c44ca9095899ab3c16a2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77fa69550f6d4718b6cf7206ec425827"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9948557bd0f74ad193b4dbe06ada35b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f6a9f04d22e4acfa7de67d8851ae928"}},"metadata":{}},{"name":"stdout","text":"Maximum context length: 131072\n","output_type":"stream"},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1538883 > 131072). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Total tokens: 1538883, Creating 752 chunks of size 2048\nLoading model to identify layer structure...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/676 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b08419d6d21c478681ecc8f6b20e7e17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edcb0f9bf17d4aaaaf3e6975f3cda596"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33dabf0a5b41439b8d233362a08728a3"}},"metadata":{}},{"name":"stdout","text":"Found 2 embedding layers: ['model.embed_tokens', 'lm_head']\nFound 196 linear layers\nApplying LoRA adapters to model...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:543: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 10,460,160 || all params: 1,554,174,464 || trainable%: 0.6730\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\n# Print training configuration\nprint(f\"\\n{'*'*70}\")\nprint(f\"ENHANCED LORA CONTINUED PRETRAINING CONFIGURATION:\")\nprint(f\"Model: {model_name}\")\nprint(f\"LoRA rank: {lora_config.r}\")\nprint(f\"Epochs: {training_args.num_train_epochs}\")\nprint(f\"Using decoupled learning rates: embedding={training_args.learning_rate/10}, other={training_args.learning_rate}\")\nprint(f\"Batch size: {training_args.per_device_train_batch_size} √ó \"\n      f\"{training_args.gradient_accumulation_steps} steps √ó \"\n      f\"{torch.cuda.device_count()} GPUs = \"\n      f\"{training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps * torch.cuda.device_count()}\")\nprint(f\"Dataset size: {len(chunked_dataset)} chunks of {chunk_size} tokens each\")\nprint(f\"{'*'*70}\\n\")\n\n# Start the training process\nprint(\"\\nüöÄ Starting research-optimized LoRA continued pretraining...\\n\")\ntry:\n    trainer.train()\n    print(\"\\n‚úÖ Training completed successfully!\")\n    # Save the final model\n    print(\"Saving final model...\")\n    model.save_pretrained(\"./qwen_math_nbody_final_lora\")\n    tokenizer.save_pretrained(\"./qwen_math_nbody_final_lora\")\n    print(\"Model saved at ./qwen_math_nbody_final_lora\")\nexcept Exception as e:\n    print(f\"\\n‚ùå Training interrupted: {e}\")\n    # Save checkpoint even if interrupted\n    print(\"Saving emergency checkpoint...\")\n    model.save_pretrained(\"./qwen_math_nbody_checkpoint_lora\")\n    tokenizer.save_pretrained(\"./qwen_math_nbody_checkpoint_lora\")\n    print(\"Emergency checkpoint saved at ./qwen_math_nbody_checkpoint_lora\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T07:13:49.227967Z","iopub.execute_input":"2025-03-10T07:13:49.228714Z","execution_failed":"2025-03-10T07:15:51.088Z"}},"outputs":[{"name":"stdout","text":"\n**********************************************************************\nENHANCED LORA CONTINUED PRETRAINING CONFIGURATION:\nModel: Qwen/Qwen2.5-Math-1.5B\nLoRA rank: 8\nEpochs: 3\nUsing decoupled learning rates: embedding=1e-05, other=0.0001\nBatch size: 1 √ó 16 steps √ó 1 GPUs = 16\nDataset size: 752 chunks of 2048 tokens each\n**********************************************************************\n\n\nüöÄ Starting research-optimized LoRA continued pretraining...\n\nUsing decoupled learning rates: embedding=1e-05, other=0.0001\n\n======================================================================\nTRAINING STARTED\n======================================================================\n\n======================================================================\nBeginning Epoch 1/3\n======================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/3:   0%|          | 0/47 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"971d43b809eb4382891baf54000ea1f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/141 : < :, Epoch 0.02/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport shutil\nfrom peft import PeftModel\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\n# 1. Load the base model\nbase_model_id = \"Qwen/Qwen2.5-Math-1.5B\"\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model_id,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\ntokenizer = AutoTokenizer.from_pretrained(base_model_id)\n\n# 2. Create a temporary directory to combine both adapter files\ntemp_adapter_dir = \"/kaggle/working/combined_adapter\"\nos.makedirs(temp_adapter_dir, exist_ok=True)\n\n# 3. Copy the adapter weights file\nweights_source = \"/kaggle/input/central_config_adapter/pytorch/default/1/adapter_model.safetensors\"\nweights_dest = os.path.join(temp_adapter_dir, \"adapter_model.safetensors\")\nshutil.copy(weights_source, weights_dest)\n\n# 4. Copy or create the config file\n# Assuming you've uploaded the config JSON to a different location\nconfig_source = \"/kaggle/input/adapter-config/adapter_config.json\"  # Update this path\nconfig_dest = os.path.join(temp_adapter_dir, \"adapter_config.json\")\nshutil.copy(config_source, config_dest)\n\n# 5. Load the model with the combined adapter\nmodel = PeftModel.from_pretrained(model, temp_adapter_dir)\n\n# 6. Test the model\nprompt = \"What are trapezoidal central configurations?\"\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\noutputs = model.generate(\n    **inputs,\n    max_new_tokens=2048,  # Increased for more detailed explanation\n    temperature=0.6,     # Lower temperature for more precise outputs\n    # do_sample=True,\n    # top_p=0.95\n)\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:19:09.642234Z","iopub.execute_input":"2025-03-10T15:19:09.642585Z","iopub.status.idle":"2025-03-10T15:20:27.459238Z","shell.execute_reply.started":"2025-03-10T15:19:09.642553Z","shell.execute_reply":"2025-03-10T15:20:27.458361Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"What are central configurations in the n-body problem? Explain with equations. Central configurations in the n-body problem are special arrangements of the bodies such that the gravitational force on each body is proportional to the position vector of that body relative to the center of mass of the system. In other words, the configuration is such that the acceleration of each body is proportional to its position vector.\n\nTo understand this mathematically, let's consider the n-body problem with masses \\( m_1, m_2, \\ldots, m_n \\) located at positions \\( \\mathbf{r}_1, \\mathbf{r}_2, \\ldots, \\mathbf{r}_n \\) in \\(\\mathbb{R}^d\\). The position vector of the center of mass is given by\n\n\\[\n\\mathbf{R} = \\frac{1}{M} \\sum_{i=1}^n m_i \\mathbf{r}_i,\n\\]\n\nwhere \\( M = \\sum_{i=1}^n m_i \\) is the total mass of the system.\n\nThe acceleration of the \\( i \\)-th body is given by\n\n\\[\n\\mathbf{a}_i = \\frac{d^2 \\mathbf{r}_i}{dt^2} = \\frac{d}{dt} \\left( \\frac{d \\mathbf{r}_i}{dt} \\right) = \\frac{d}{dt} \\left( \\frac{d}{dt} \\left( \\frac{\\mathbf{r}_i - \\mathbf{R}}{M} \\right) \\right) = \\frac{d}{dt} \\left( \\frac{\\mathbf{r}_i - \\mathbf{R}}{M} \\right) = \\frac{d}{dt} \\left( \\frac{\\mathbf{r}_i - \\mathbf{R}}{M} \\right) = \\frac{d}{dt} \\left( \\frac{\\mathbf{r}_i - \\mathbf{R}}{M} \\right).\n\\]\n\nThe gravitational force on the \\( i \\)-th body is given by\n\n\\[\n\\mathbf{F}_i = -\\frac{G m_i}{r_{ij}^3} \\mathbf{r}_{ij},\n\\]\n\nwhere \\( r_{ij} = \\|\\mathbf{r}_i - \\mathbf{r}_j\\| \\) is the distance between the \\( i \\)-th and \\( j \\)-th bodies, and \\( \\mathbf{r}_{ij} = \\mathbf{r}_i - \\mathbf{r}_j \\) is the position vector from the \\( j \\)-th body to the \\( i \\)-th body. The total force on the \\( i \\)-th body is the sum of the gravitational forces from all the other bodies:\n\n\\[\n\\mathbf{F}_i = \\sum_{j \\neq i} \\mathbf{F}_{ij} = \\sum_{j \\neq i} -\\frac{G m_i m_j}{r_{ij}^3} \\mathbf{r}_{ij}.\n\\]\n\nIn a central configuration, the acceleration of each body is proportional to its position vector relative to the center of mass. Therefore, we have\n\n\\[\n\\mathbf{a}_i = \\lambda \\mathbf{r}_i - \\lambda \\mathbf{R} = \\lambda (\\mathbf{r}_i - \\mathbf{R}),\n\\]\n\nfor some constant \\(\\lambda\\). Substituting the expressions for \\(\\mathbf{a}_i\\) and \\(\\mathbf{F}_i\\) into this equation, we get\n\n\\[\n\\sum_{j \\neq i} -\\frac{G m_i m_j}{r_{ij}^3} \\mathbf{r}_{ij} = \\lambda (\\mathbf{r}_i - \\mathbf{R}).\n\\]\n\nThis equation must hold for all \\( i = 1, 2, \\ldots, n \\). Therefore, we have\n\n\\[\n\\sum_{j \\neq i} -\\frac{G m_i m_j}{r_{ij}^3} \\mathbf{r}_{ij} = \\lambda \\mathbf{r}_i - \\lambda \\mathbf{R}.\n\\]\n\nThis is the equation that defines a central configuration. It is a system of \\( n \\) equations in \\( nd \\) unknowns (the coordinates of the \\( n \\) bodies in \\(\\mathbb{R}^d\\)).\n\nIn summary, a central configuration in the n-body problem is a configuration of the bodies such that the acceleration of each body is proportional to its position vector relative to the center of mass. The equation that defines a central configuration is\n\n\\[\n\\boxed{\\sum_{j \\neq i} -\\frac{G m_i m_j}{r_{ij}^3} \\mathbf{r}_{ij} = \\lambda \\mathbf{r}_i - \\lambda \\mathbf{R}}.\n\\]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"prompt = \"What are trapezoidal central configurations?\"\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\noutputs = model.generate(\n    **inputs,\n    max_new_tokens=2048,  # Increased for more detailed explanation\n    temperature=0.6,     # Lower temperature for more precise outputs\n    # do_sample=True,\n    # top_p=0.95\n)\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:22:06.254311Z","iopub.execute_input":"2025-03-10T15:22:06.254655Z","iopub.status.idle":"2025-03-10T15:22:28.774471Z","shell.execute_reply.started":"2025-03-10T15:22:06.254630Z","shell.execute_reply":"2025-03-10T15:22:28.773732Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"What are trapezoidal central configurations? And how are they related to the spatial 4-body problem?\nTrapezoidal central configurations are a type of central configuration in the spatial 4-body problem. In this context, a central configuration is a special arrangement of the bodies in which the acceleration vector of each body is proportional to the position vector of that body with respect to the center of mass of the system.\n\nIn the case of trapezoidal central configurations, the bodies are arranged in a trapezoidal shape, with two bodies at the top and two bodies at the bottom. The bodies at the top are connected by a line segment, and the bodies at the bottom are also connected by a line segment. The two line segments are parallel to each other, and the two bodies at the top are connected to the two bodies at the bottom by line segments that are perpendicular to the line segments connecting the bodies at the top and bottom.\n\nThe spatial 4-body problem is a problem in classical mechanics that involves the motion of four bodies under the influence of their mutual gravitational attraction. The problem is to find the positions and velocities of the bodies at any given time, given their initial positions and velocities.\n\nTrapezoidal central configurations are related to the spatial 4-body problem because they are a special type of central configuration that can be used to study the motion of the bodies in the problem. In particular, trapezoidal central configurations can be used to find the equilibrium points of the problem, which are the points in space where the acceleration of each body is zero. These equilibrium points are important because they can be used to understand the behavior of the bodies in the problem.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"prompt = \"Explain the concept of bifurcation and the stacking of central configurations in the planar $1+4$ body problem. Include relevant mathematical equations or expressions.\"\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\noutputs = model.generate(\n    **inputs,\n    max_new_tokens=2048,  # Increased for more detailed explanation\n    temperature=0.6,     # Lower temperature for more precise outputs\n    # do_sample=True,\n    # top_p=0.95\n)\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:29:12.649498Z","iopub.execute_input":"2025-03-10T15:29:12.649797Z","iopub.status.idle":"2025-03-10T15:30:33.113934Z","shell.execute_reply.started":"2025-03-10T15:29:12.649775Z","shell.execute_reply":"2025-03-10T15:30:33.113146Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Explain the concept of bifurcation and the stacking of central configurations in the planar $1+4$ body problem. Include relevant mathematical equations or expressions. Bifurcation in the context of the planar $1+4$ body problem refers to the phenomenon where a central configuration (CC) of the system undergoes a qualitative change as a parameter is varied. A central configuration is a special arrangement of the bodies such that the acceleration vector of each body is proportional to the position vector of that body relative to the center of mass of the system. In the planar $1+4$ body problem, we have one body at the origin and four bodies at the vertices of a square.\n\nTo understand the concept of bifurcation, let's consider the planar $1+4$ body problem with masses $m_1, m_2, m_3, m_4$ at the vertices of a square and mass $m_5$ at the origin. The positions of the bodies are given by:\n\\[\n\\mathbf{r}_1 = (0,0), \\quad \\mathbf{r}_2 = (a,0), \\quad \\mathbf{r}_3 = (a,a), \\quad \\mathbf{r}_4 = (0,a), \\quad \\mathbf{r}_5 = (0,0)\n\\]\nwhere $a$ is the side length of the square. The center of mass of the system is at the origin, so the position vector of the center of mass is $\\mathbf{r}_{\\text{cm}} = (0,0)$.\n\nA central configuration is a solution to the following system of equations:\n\\[\nm_i \\mathbf{r}_i = \\lambda \\sum_{j \\neq i} \\frac{m_j (\\mathbf{r}_j - \\mathbf{r}_i)}{r_{ij}^3}, \\quad i = 1,2,3,4,5\n\\]\nwhere $\\lambda$ is a constant and $r_{ij} = \\|\\mathbf{r}_i - \\mathbf{r}_j\\|$ is the distance between bodies $i$ and $j$. For the planar $1+4$ body problem, the equations of motion are:\n\\[\nm_1 \\mathbf{r}_1 = 0, \\quad m_2 \\mathbf{r}_2 = \\lambda \\left( \\frac{m_1 (\\mathbf{r}_1 - \\mathbf{r}_2)}{r_{12}^3} + \\frac{m_3 (\\mathbf{r}_3 - \\mathbf{r}_2)}{r_{32}^3} + \\frac{m_4 (\\mathbf{r}_4 - \\mathbf{r}_2)}{r_{42}^3} \\right), \\quad m_3 \\mathbf{r}_3 = \\lambda \\left( \\frac{m_1 (\\mathbf{r}_1 - \\mathbf{r}_3)}{r_{13}^3} + \\frac{m_2 (\\mathbf{r}_2 - \\mathbf{r}_3)}{r_{23}^3} + \\frac{m_4 (\\mathbf{r}_4 - \\mathbf{r}_3)}{r_{43}^3} \\right)\n\\]\n\\[\nm_4 \\mathbf{r}_4 = \\lambda \\left( \\frac{m_1 (\\mathbf{r}_1 - \\mathbf{r}_4)}{r_{14}^3} + \\frac{m_2 (\\mathbf{r}_2 - \\mathbf{r}_4)}{r_{24}^3} + \\frac{m_3 (\\mathbf{r}_3 - \\mathbf{r}_4)}{r_{34}^3} \\right), \\quad m_5 \\mathbf{r}_5 = 0\n\\]\nwhere $\\mathbf{r}_5 = (0,0)$.\n\nA bifurcation occurs when a central configuration undergoes a qualitative change as a parameter is varied. In the planar $1+4$ body problem, a bifurcation can occur when the masses $m_1, m_2, m_3, m_4$ are varied. For example, if we vary $m_1$ while keeping the other masses fixed, a bifurcation can occur when $m_1$ passes through a critical value. At this critical value, the central configuration changes from a square to a rhombus or a rectangle.\n\nThe stacking of central configurations refers to the phenomenon where a central configuration of the system can be obtained by stacking smaller central configurations. In the planar $1+4$ body problem, a central configuration can be obtained by stacking two central configurations of the $1+2$ body problem. For example, if we have two central configurations of the $1+2$ body problem with masses $m_1$ and $m_2$ at the vertices of an isosceles triangle and mass $m_3$ at the center, we can stack these two central configurations to obtain a central configuration of the $1+4$ body problem with masses $m_1, m_2, m_3, m_4$ at the vertices of a square and mass $m_5$ at the center.\n\nIn summary, a bifurcation in the planar $1+4$ body problem is a qualitative change in a central configuration as a parameter is varied. The stacking of central configurations refers to the phenomenon where a central configuration of the system can be obtained by stacking smaller central configurations.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"prompt = (\n    \"You are an expert on central configurations in mathematical physics. \"\n    \"Please explain what co-circular central configurations are and show one derivation equation step-by-step.\"\n)\n\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\noutputs = model.generate(\n    **inputs,\n    max_new_tokens=2048,  # Increased for more detailed explanation\n    temperature=0.7,     # Lower temperature for more precise outputs\n    do_sample=True,\n    top_p=0.95,\n    repetition_penalty = 1.1\n)\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:41:27.477313Z","iopub.execute_input":"2025-03-10T15:41:27.477632Z","iopub.status.idle":"2025-03-10T15:43:47.340219Z","shell.execute_reply.started":"2025-03-10T15:41:27.477609Z","shell.execute_reply":"2025-03-10T15:43:47.339354Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"You are an expert on central configurations in mathematical physics. Please explain what co-circular central configurations are and show one derivation equation step-by-step. Co-circular central configurations refer to a type of central configuration in which the particles lie on a common circle.\n\nConsider three point masses $m_{1}, m_{2}$, and $m_{3}$ located at vertices of a triangle with positive area $\\Delta$. Let $x_{i j}$ be the distance between masses $m_{i}$ and $m_{j}$. The mutual gravitational potential energy is given by\n\n$$\nU=\\frac{1}{2} \\sum_{1 \\leq i<j \\leq 3} m_{i} m_{j} / x_{i j}\n$$\n\nLet $r$ denote the radius of the circumscribed circle. Without loss of generality we can assume that the center of mass is at the origin, then there exist $\\theta_{i} \\in[0,2 \\pi)$ such that $x_{i}=e^{i \\theta_{i}}$, where $x_{i}=x_{i 1} e^{i \\theta_{i}}$ for $i=1,2,3$. In terms of $\\left(\\theta_{i}\\right)_{i=1}^{3}$, we have\n\n$$\n\\begin{gathered}\nx_{12}=r|\\sin (\\theta_{1}-\\theta_{2})| \\\\\nx_{13}=r|\\sin (\\theta_{1}-\\theta_{3})| \\\\\nx_{23}=r|\\sin (\\theta_{2}-\\theta_{3})|\n\\end{gathered}\n$$\n\nwhere the absolute value ensures that the distances are positive. By convention, if $\\theta_{1}<\\theta_{2}<\\theta_{3}$ or $\\theta_{1}>\\theta_{3}>\\theta_{2}$, then $x_{12}=r|\\sin (\\theta_{1}-\\theta_{2})|$; otherwise $x_{12}=r|\\sin (\\theta_{2}-\\theta_{1})|$. Similarly for other pairs of indices. The condition that all points are distinct implies that $\\theta_{1} \\neq \\theta_{2}$, $\\theta_{1} \\neq \\theta_{3}$, and $\\theta_{2} \\neq \\theta_{3}$. Furthermore, we must have $\\theta_{1}, \\theta_{2}$, and $\\theta_{3}$ are not equally spaced angles since otherwise the three points would be collinear. Note that any permutation of $(\\theta_{1}, \\theta_{2}, \\theta_{3})$ results in the same set of distances $\\left(x_{12}, x_{13}, x_{23}\\right)$.\n\nThe Newtonian equations of motion are given by\n\n$$\n\\ddot{\\mathbf{x}}_{i}=-\\nabla_{\\mathbf{x}_{i}} U=\\sum_{\\substack{j=1 \\\\ j \\neq i}}^{3} m_{j} \\frac{\\mathbf{x}_{i}-\\mathbf{x}_{j}}{x_{i j}^{3}}\n$$\n\nWe choose our coordinates so that $m_{1}$ is fixed at the north pole and $m_{2}$ and $m_{3}$ are symmetrically placed about the equator (see Figure 2). Then their positions are given by $\\mathbf{x}_{2}=\\left(r \\cos \\theta, r \\sin \\theta, 0\\right)$ and $\\mathbf{x}_{3}=\\left(r \\cos \\theta,-r \\sin \\theta, 0\\right)$ for some $\\theta \\in[0, \\pi)$. We introduce new variables $a=$ $-x_{12}=-(r \\sin \\theta)>0$ and $b=x_{13}=r \\sin \\alpha>0$. Using Eqs. (7), (8), (9), and (10), we obtain\n\n$$\n\\begin{array}{lll}\nm_{2} & = & \\frac{m_{1}}{\\left(1+a^{2}\\right)^{3 / 2}} \\\\\nm_{3} & = & \\frac{m_{1}}{\\left(b^{2}+1\\right)^{3 / 2}} \\\\\n& = & \\frac{m_{1}}{\\left(a^{2}+4 b^{2}+1\\right)^{3 / 2}} \\\\\na & = & \\frac{2 r}{\\sqrt{1+b^{2}}} \\\\\nb & = & \\frac{2 r}{\\sqrt{4 b^{2}+1}}\n\\end{array}\n$$\n\nBy eliminating $b$, we get\n\n$$\n-\\frac{m_{1}}{m_{3}}=\\frac{4(1+a^{2})(a^{2}+4)}{(1-b^{2}) \\sqrt{4 b^{2}+1}}=\\frac{\\left(1+a^{2}\\right)\\left(a^{2}+4\\right)(a^{2}+4 b^{2})}{\\left(a^{2}+4 b^{2}+1\\right)^{3 / 2}(a^{2}-1)}\n$$\n\nAfter algebraic simplification, Eq. (11) becomes\n\n$$\n\\left(1+a^{2}\\right)\\left(a^{2}+4\\right)=\\left(1+a^{2}+4 b^{2}\\right)^{3 / 2}\n$$\n\nSince $a=\\frac{2 r}{\\sqrt{1+b^{2}}}$,\n\n$$\n\\begin{aligned}\n\\frac{r^{2}}{1+b^{2}} & =\\frac{\\left(1+\\frac{4 r^{2}}{1+b^{2}}\\right)^{3 / 2}}{16} \\\\\n1+b^{2} & =\\frac{4 r^{2}}{\\left(1+\\frac{4 r^{2}}{1+b^{2}}\\right)^{3 / 2}} \\\\\n\\Rightarrow & \\quad\\left(1+b^{2}\\right)^{5 / 2}=4 r^{2}\\left(1+\\frac{4 r^{2}}{1+b^{2}}\\right)^{3 / 2}\n\\end{aligned}\n$$\n\nThe above equation has two solutions corresponding to the equilateral triangle case when $\\theta=\\pi / 3$, and the collinear case when $\\theta=0$ or $\\theta=\\pi$. There are no solutions for $0<\\theta<\\pi / 3$ or $\\pi / 3<\\theta<\\pi$ because $a<b$. Thus, the only possible co-circular central configurations occur when $\\theta=0$ or $\\theta=\\pi$.\nIf $\\theta=0$ then $m_{1}, m_{2}$, and $m_{3}$ are collinear. So from Eq. (10) we find that\n\n$$\n\\begin{aligned}\n& \\frac{m_{1}}{m_{2}}=\\frac{\\left(r^{2}-1\\right)^{3 / 2}}{r^{3}} \\\\\n& \\frac{m_{2}}{m_{3}}=\\frac{\\left(r^{2}+1\\right)^{3 / 2}}{r^{3}} \\\\\n& \\frac{m_{3}}{m_{1}}=\\frac{r^{3}}{\\left(r^{2}-1\\right)^{3 / 2}\\left(r^{2}+1\\right)^{3 / 2}}\n\\end{aligned}\n$$\n\nNote that for any choice of $m_{1}>0$, $m_{2}>0$ and $m_{3}>0$ satisfying the above relations, it follows that $m_{1}+m_{2}+m_{3}>0$, which is necessary for the existence of a central configuration.\n\nIf $\\theta=\\pi$ then the three bodies form an equilateral triangle. From Eq. (10) we find that\n\n$$\n\\begin{aligned}\n& \\frac{m_{1}}{m_{2}}=\\frac{\\left(r^{2}+1\\right)^{3 / 2}}{r^{3}} \\\\\n& \\frac{m_{2}}{m_{3}}=\\frac{\\left(r^{2}-1\\right)^{3 / 2}}{r^{3}} \\\\\n& \\frac{m_{3}}{m_{1}}=\\frac{r^{3}}{\\left(r^{2}+1\\right)^{3 / 2}\\left(r^{2}-1\\right)^{3 / 2}}\n\\end{aligned}\n$$\n\nAgain, for any choice of $m_{1}>0$, $m_{2}>0$ and $m_{3}>0$ satisfying the above relations, it follows that $m_{1}+m_{2}+m_{3}>0$, which is necessary for the existence of a central configuration.\n\nThus, we have obtained a complete description of the co-circular central configurations up to congruence for four equal masses. For more details, see Section 3 of .\n\n# 2. Generalized co-circular central configurations \n\nA generalized co-circular central configuration is defined as follows. Consider a system consisting of $N$ point masses located at position vectors $q_{1}, q_{2}, \\ldots, q_{N}$ in $\\mathbb{R}^{d}$, where $d$ is either 2 or 3. Assume that these $N$ bodies are constrained to lie on a circle of radius $r$ in $\\mathbb{R}^{d}$\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/galactica-30b\")\nmodel = AutoModelForCausalLM.from_pretrained(\"facebook/galactica-30b\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:51:27.279491Z","iopub.execute_input":"2025-03-10T15:51:27.279829Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/166 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1dd1202f34d49c788d6605ad1fadb57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cda5cd3cf744c809fbbf6fb8f467e5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b93a07a13e3d4312a2836ae91c7fa804"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/754 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f944455e73c14ed49de858ef63829b84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/67.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54776758e3074097893734711e2a0d9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f46b86ea8f4040d1a39c57569ce59e7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00007.bin:   0%|          | 0.00/9.79G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5ae2d179c414a7c9b458923988e091b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00007.bin:   0%|          | 0.00/9.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f8d748805d048679c93d8e31b2f210c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00003-of-00007.bin:   0%|          | 0.00/9.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91dee30e2e994a758cc817d36de95568"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# Move the model to GPU\nmodel = model.to(\"cuda\")\n\ninput_text = (\"Explain the concept of bifurcation and the stacking of central configurations in the planar \"\n              \"$1+4$ body problem. Include relevant mathematical equations or expressions.\")\n# Transfer input tokens to GPU\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n\n# Generate output tokens\noutputs = model.generate(input_ids, max_length=1000)\n\n# Decode and print the generated text\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:50:14.286376Z","iopub.execute_input":"2025-03-10T15:50:14.286712Z","iopub.status.idle":"2025-03-10T15:50:28.264315Z","shell.execute_reply.started":"2025-03-10T15:50:14.286690Z","shell.execute_reply":"2025-03-10T15:50:28.263553Z"}},"outputs":[{"name":"stdout","text":"Explain the concept of bifurcation and the stacking of central configurations in the planar $1+4$ body problem. Include relevant mathematical equations or expressions.\n\n\nAnswer:\n\nI'm not sure what you mean by \"central configuration\", but I think you mean \"a configuration of the bodies where the sum of the gravitational forces on each body is zero\".\nThe [central configuration](https://en.wikipedia.org/wiki/Central_configuration) is a configuration of the bodies where the sum of the gravitational forces on each body is zero.\nThe [bifurcation](https://en.wikipedia.org/wiki/Bifurcation_theory) is a change in the number of solutions of a system of equations.\nThe [stacking](https://en.wikipedia.org/wiki/Stacking_(dynamics)) is a change in the number of solutions of a system of equations.\n\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Move the model to GPU\nmodel = model.to(\"cuda\")\n\ninput_text = (\"Explain the concept of bifurcation and the stacking of central configurations in the planar \"\n              \"$1+4$ body problem. Include relevant mathematical equations or expressions.\")\n# Transfer input tokens to GPU\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n\n# Generate output tokens\noutputs = model.generate(input_ids, max_length=1000)\n\n# Decode and print the generated text\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}